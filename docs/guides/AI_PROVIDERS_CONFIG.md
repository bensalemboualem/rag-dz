# ü§ñ Configuration des Providers AI

Guide complet pour configurer tous les providers IA dans RAG.dz

## üìä √âtat Actuel

### ‚úÖ Backend RAG.dz
- **Provider:** Anthropic Claude
- **Mod√®le:** claude-3-5-sonnet-20241022
- **Status:** ‚úÖ Actif et fonctionnel

### ‚úÖ Bolt.diy
- **Providers configur√©s:** Tous (10+ providers)
- **Status:** ‚úÖ Pr√™t √† l'emploi

### ‚úÖ BMAD/Archon
- **Int√©gration:** Backend API
- **Status:** ‚úÖ Actif via routes `/api/bmad/*`

---

## üîë Providers Configur√©s

### 1. **Anthropic Claude** (Principal - Recommand√©)
```bash
ANTHROPIC_API_KEY=sk-ant-api03-KXm...
LLM_PROVIDER=anthropic
LLM_MODEL=claude-3-5-sonnet-20241022
```

**Mod√®les disponibles:**
- `claude-3-5-sonnet-20241022` (Recommand√©)
- `claude-3-opus-20240229` (Le plus puissant)
- `claude-3-sonnet-20240229`
- `claude-3-haiku-20240307` (Le plus rapide)

**Avantages:**
- ‚úÖ Meilleure compr√©hension contextuelle
- ‚úÖ Excellente qualit√© de g√©n√©ration
- ‚úÖ Support multilingue (FR/AR/EN)
- ‚úÖ 200K tokens de contexte
- ‚úÖ Recommand√© pour BMAD/Archon

---

### 2. **OpenAI GPT**
```bash
OPENAI_API_KEY=sk-proj-ysv...
LLM_PROVIDER=openai
LLM_MODEL=gpt-4-turbo
```

**Mod√®les disponibles:**
- `gpt-4-turbo` (Le plus performant)
- `gpt-4` (Stable)
- `gpt-3.5-turbo` (√âconomique)

**Avantages:**
- ‚úÖ Rapide et fiable
- ‚úÖ Bon rapport qualit√©/prix (3.5-turbo)
- ‚úÖ Excellente documentation

---

### 3. **DeepSeek** (√âconomique)
```bash
DEEPSEEK_API_KEY=sk-e2d...
LLM_PROVIDER=deepseek
LLM_MODEL=deepseek-chat
```

**Avantages:**
- ‚úÖ Tr√®s √©conomique (5-10x moins cher)
- ‚úÖ Bonnes performances
- ‚úÖ Support du code

---

### 4. **Groq** (Le Plus Rapide)
```bash
GROQ_API_KEY=gsk_mw3...
LLM_PROVIDER=groq
LLM_MODEL=llama-3.1-70b-versatile
```

**Mod√®les disponibles:**
- `llama-3.1-70b-versatile`
- `mixtral-8x7b-32768`
- `gemma-7b-it`

**Avantages:**
- ‚úÖ Vitesse extr√™me (500+ tokens/sec)
- ‚úÖ Gratuit (avec limites)
- ‚úÖ Parfait pour d√©veloppement

---

### 5. **Google Gemini**
```bash
GOOGLE_GENERATIVE_AI_API_KEY=AIza...
LLM_PROVIDER=google
LLM_MODEL=gemini-1.5-pro
```

**Avantages:**
- ‚úÖ Multimodal (texte + images)
- ‚úÖ Grand contexte (1M tokens)
- ‚úÖ Gratuit (avec limites)

---

### 6. **Autres Providers Disponibles**

**Mistral AI:**
```bash
MISTRAL_API_KEY=U4TD...
# Mod√®les: mistral-large, mistral-medium, mistral-small
```

**Cohere:**
```bash
COHERE_API_KEY=bAVV...
# Mod√®les: command-r-plus, command-r
```

**Together AI:**
```bash
TOGETHER_API_KEY=99ac...
# Nombreux mod√®les open-source
```

**OpenRouter (Meta-routing):**
```bash
OPEN_ROUTER_API_KEY=sk-or-v1-b096...
# Acc√®s √† tous les providers via une seule API
```

---

## üîß Configuration par Service

### Backend RAG.dz (`.env` racine)

```bash
# ==============================================
# Cloud LLM Configuration
# ==============================================
LLM_PROVIDER=anthropic
LLM_MODEL=claude-3-5-sonnet-20241022
ENABLE_LLM=true

# Cl√©s API
ANTHROPIC_API_KEY=sk-ant-api03-...
OPENAI_API_KEY=sk-proj-...
DEEPSEEK_API_KEY=sk-e2d...
GROQ_API_KEY=gsk_mw3...
GOOGLE_GENERATIVE_AI_API_KEY=AIza...
```

### Bolt.diy (`bolt-diy/.env.local`)

Toutes les cl√©s AI sont d√©j√† configur√©es dans le fichier existant.

---

## üéØ Changer de Provider

### Via Variables d'Environnement

**1. Modifier `.env`:**
```bash
# Passer √† OpenAI GPT-4
LLM_PROVIDER=openai
LLM_MODEL=gpt-4-turbo

# Ou passer √† DeepSeek
LLM_PROVIDER=deepseek
LLM_MODEL=deepseek-chat

# Ou passer √† Groq (rapide)
LLM_PROVIDER=groq
LLM_MODEL=llama-3.1-70b-versatile
```

**2. Red√©marrer le backend:**
```bash
docker-compose restart backend
```

**3. V√©rifier:**
```bash
docker exec ragdz-backend python -c "from app.clients.cloud_llm import CloudLLMClient; client = CloudLLMClient(); print('Provider:', client.provider); print('Model:', client.model)"
```

---

## üí∞ Co√ªts Estim√©s

### Par Provider (pour 1M tokens)

| Provider | Input | Output | Total (1M tokens) |
|----------|-------|--------|-------------------|
| **GPT-4 Turbo** | $10 | $30 | ~$40 |
| **GPT-3.5 Turbo** | $0.50 | $1.50 | ~$2 |
| **Claude Sonnet** | $3 | $15 | ~$18 |
| **Claude Haiku** | $0.25 | $1.25 | ~$1.50 |
| **DeepSeek** | $0.14 | $0.28 | ~$0.42 |
| **Groq** | Gratuit* | Gratuit* | Gratuit* |
| **Gemini** | Gratuit* | Gratuit* | Gratuit* |

*Avec limites quotidiennes

### üí° Recommandations √âconomiques

1. **D√©veloppement:** Groq (gratuit) ou DeepSeek (tr√®s √©conomique)
2. **Production petit volume:** Claude Haiku ou GPT-3.5-turbo
3. **Production qualit√©:** Claude Sonnet ou GPT-4
4. **Production gros volume:** DeepSeek ou Claude Haiku

---

## üß™ Tester un Provider

### Via API

```bash
# Test avec curl
curl -X POST http://localhost:8180/api/query \
  -H "Content-Type: application/json" \
  -H "X-API-Key: ragdz_dev_demo_key_..." \
  -d '{
    "query": "Bonjour, comment vas-tu ?",
    "max_results": 3
  }'
```

### Via Python (dans le container)

```bash
docker exec -it ragdz-backend python
```

```python
from app.clients.cloud_llm import CloudLLMClient

client = CloudLLMClient()
print(f"Provider: {client.provider}")
print(f"Model: {client.model}")
print(f"Available: {client.is_available()}")

# Test de g√©n√©ration
response = client.generate(
    prompt="Dis bonjour en fran√ßais",
    temperature=0.7,
    max_tokens=100
)
print(f"Response: {response}")
```

---

## üîí S√©curit√© des Cl√©s API

### ‚ö†Ô∏è IMPORTANT

- ‚úÖ **NE JAMAIS** commiter `.env` dans Git
- ‚úÖ Utiliser `.env.example` comme template
- ‚úÖ Ajouter `.env` au `.gitignore`
- ‚úÖ Utiliser des cl√©s diff√©rentes dev/prod
- ‚úÖ Rotation r√©guli√®re des cl√©s

### Prot√©ger vos cl√©s:

```bash
# .gitignore (d√©j√† configur√©)
.env
.env.local
.env.*.local
**/.env.local
```

---

## üêõ Debugging

### Le LLM ne fonctionne pas?

**1. V√©rifier la configuration:**
```bash
docker exec ragdz-backend env | grep -E "LLM|ANTHROPIC|OPENAI"
```

**2. V√©rifier la connexion:**
```bash
docker exec ragdz-backend python -c "
from app.clients.cloud_llm import CloudLLMClient
client = CloudLLMClient()
print('Available:', client.is_available())
print('Provider:', client.provider)
"
```

**3. V√©rifier les logs:**
```bash
docker logs ragdz-backend --tail 50 | grep -i "llm\|anthropic\|openai"
```

**4. Tester manuellement:**
```bash
# OpenAI
curl https://api.openai.com/v1/chat/completions \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{"model":"gpt-3.5-turbo","messages":[{"role":"user","content":"Hello"}]}'

# Anthropic
curl https://api.anthropic.com/v1/messages \
  -H "x-api-key: $ANTHROPIC_API_KEY" \
  -H "anthropic-version: 2023-06-01" \
  -H "Content-Type: application/json" \
  -d '{"model":"claude-3-5-sonnet-20241022","max_tokens":100,"messages":[{"role":"user","content":"Hello"}]}'
```

---

## üìö Ressources

### Documentation Officielle

- **Anthropic:** https://docs.anthropic.com/
- **OpenAI:** https://platform.openai.com/docs
- **DeepSeek:** https://platform.deepseek.com/docs
- **Groq:** https://console.groq.com/docs
- **Google AI:** https://ai.google.dev/docs

### Obtenir des API Keys

- **Anthropic:** https://console.anthropic.com/
- **OpenAI:** https://platform.openai.com/api-keys
- **DeepSeek:** https://platform.deepseek.com/api_keys
- **Groq:** https://console.groq.com/keys
- **Google:** https://makersuite.google.com/app/apikey

---

## ‚úÖ Configuration Actuelle V√©rifi√©e

‚úÖ Backend RAG.dz ‚Üí Anthropic Claude Sonnet 3.5
‚úÖ Bolt.diy ‚Üí Tous providers configur√©s
‚úÖ BMAD ‚Üí Utilise le backend (Claude)
‚úÖ Archon ‚Üí Utilise le backend (Claude)

**Tout est pr√™t √† l'emploi!** üöÄ
